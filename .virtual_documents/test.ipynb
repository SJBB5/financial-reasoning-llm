%run run_demo.py








import json
import os
from datetime import datetime

def log_llm_output(model, temperature, max_tokens, output, ticker=None, log_file="llm_output_log.json"):
    # Create log entry
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "ticker": ticker,
        "output": output,
        "output_length": len(output)
    }
    
    # Load existing logs or create new list
    logs = []
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r') as f:
                logs = json.load(f)
        except (json.JSONDecodeError, IOError):
            logs = []
    
    # Append new entry
    logs.append(log_entry)
    
    # Write back to file
    with open(log_file, 'w') as f:
        json.dump(logs, f, indent=2)
    
    print(f"Logged output to {log_file}")
    return log_entry


def run_and_log(log_file="llm_output_log.json"):
    from run_demo import main as run_demo_main
    
    # Run the demo
    results = run_demo_main()
    
    if results is None:
        print("Demo failed - no results to log")
        return None
    
    # Extract data and log automatically
    config = results.get("llm_config", {})
    log_llm_output(
        model=config.get("model"),
        temperature=config.get("temperature"),
        max_tokens=config.get("max_tokens"),
        output=results.get("explanation"),
        ticker=results.get("ticker"),
        log_file=log_file
    )
    
    return results
